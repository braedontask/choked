# Welcome to Choked

Choked is a simple and powerful Python rate limiting library that uses the token bucket algorithm to control the rate of function calls.

## Features

- **Easy to use**: Simple decorator-based API
- **Flexible backends**: Supports both Redis and proxy service backends
- **Async/Sync support**: Works with both synchronous and asynchronous functions
- **Exponential backoff**: Smart retry logic with jitter to prevent thundering herd
- **Distributed**: Share rate limits across multiple processes or servers
- **Multi-worker scaling**: Perfect for managing multiple workers using the same API key without manual rate limit tuning

## Quick Start

Install choked:

```bash
pip install choked
```

Use the decorator:

```python
from choked import choked

@choked(key="api_calls", max_tokens=10, refill_period=60)
def make_api_call():
    # This function is rate limited to 10 calls per minute
    return "API response"

# The decorator handles rate limiting automatically
make_api_call()  # Works immediately
```

## How it Works

Choked uses a **token bucket algorithm**:

1. Each bucket has a maximum number of tokens (`max_tokens`)
2. Tokens refill at a steady rate (`max_tokens / refill_period` per second)
3. Each function call consumes one token
4. When no tokens are available, the function waits with exponential backoff

This allows for burst traffic while maintaining an average rate limit.

## Perfect for Multi-Worker Scenarios

Choked excels when you have **multiple workers sharing the same API key** and need to scale without manual rate limit tuning:

```python
# All workers automatically coordinate through Redis
@choked(key="shared_api_key", max_tokens=1000, refill_period=3600)  # 1000/hour
def worker_api_call():
    return make_external_api_call()

# Scale from 1 to 100 workers - no configuration changes needed!
# Each worker competes for tokens from the shared bucket
# Automatic load balancing and coordination
```

**Benefits:**
- **Auto-scaling**: Add/remove workers without changing rate limits
- **No manual tuning**: No need to calculate per-worker limits
- **Fair distribution**: Workers automatically share available capacity
- **Prevents overages**: Never exceed your API provider's limits
