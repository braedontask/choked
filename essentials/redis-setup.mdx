# Redis Setup

Set up Redis for distributed rate limiting with Choked across multiple processes and servers.

## Why Redis?

Redis provides distributed state management for token buckets, enabling:

- **Multi-process coordination**: Share rate limits across multiple Python processes
- **Multi-server scaling**: Coordinate rate limits across different servers
- **Persistence**: Rate limit state survives application restarts
- **Performance**: Sub-millisecond token bucket operations

## Installation

### Local Development

#### macOS (using Homebrew)
```bash
brew install redis
brew services start redis
```

#### Ubuntu/Debian
```bash
sudo apt update
sudo apt install redis-server
sudo systemctl start redis-server
sudo systemctl enable redis-server
```

#### Windows (using WSL or Docker)
```bash
# Using Docker
docker run -d -p 6379:6379 --name redis redis:alpine

# Using WSL with Ubuntu
sudo apt install redis-server
sudo service redis-server start
```

### Production Deployment

#### Docker Compose
```yaml
# docker-compose.yml
version: '3.8'
services:
  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    restart: unless-stopped
    command: redis-server --appendonly yes

  app:
    build: .
    environment:
      - CHOKED_REDIS_URL=redis://redis:6379/0
    depends_on:
      - redis

volumes:
  redis_data:
```

#### Kubernetes
```yaml
# redis-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis
spec:
  replicas: 1
  selector:
    matchLabels:
      app: redis
  template:
    metadata:
      labels:
        app: redis
    spec:
      containers:
      - name: redis
        image: redis:7-alpine
        ports:
        - containerPort: 6379
        volumeMounts:
        - name: redis-storage
          mountPath: /data
      volumes:
      - name: redis-storage
        persistentVolumeClaim:
          claimName: redis-pvc
---
apiVersion: v1
kind: Service
metadata:
  name: redis
spec:
  selector:
    app: redis
  ports:
  - port: 6379
    targetPort: 6379
```

## Configuration

### Basic Configuration

Set the Redis URL via environment variable:

```bash
export CHOKED_REDIS_URL="redis://localhost:6379/0"
```

Or in your application:

```python
import os
os.environ['CHOKED_REDIS_URL'] = 'redis://localhost:6379/0'

from choked import choked

@choked(key="api_calls", max_tokens=10, refill_period=60)
def my_function():
    return "Rate limited with Redis"
```

### Connection URL Formats

```python
# Basic connection
CHOKED_REDIS_URL = "redis://localhost:6379/0"

# With password
CHOKED_REDIS_URL = "redis://:password@localhost:6379/0"

# With username and password
CHOKED_REDIS_URL = "redis://username:password@localhost:6379/0"

# SSL/TLS connection
CHOKED_REDIS_URL = "rediss://localhost:6380/0"

# Redis Sentinel
CHOKED_REDIS_URL = "redis+sentinel://localhost:26379/mymaster/0"

# Redis Cluster
CHOKED_REDIS_URL = "redis://localhost:7000,localhost:7001,localhost:7002/0"
```

### Advanced Redis Configuration

#### Redis Configuration File (`redis.conf`)
```ini
# Performance
maxmemory 256mb
maxmemory-policy allkeys-lru

# Persistence (for rate limit durability)
save 900 1
save 300 10
save 60 10000

# Network
bind 0.0.0.0
port 6379
timeout 0
keepalive 300

# Security
requirepass your_secure_password
```

#### Connection Pool Settings
```python
import redis
from choked.token_bucket.redis_token_bucket import RedisTokenBucket

# Custom Redis connection
redis_client = redis.Redis(
    host='localhost',
    port=6379,
    db=0,
    password='your_password',
    socket_connect_timeout=5,
    socket_timeout=5,
    retry_on_timeout=True,
    health_check_interval=30
)

# Use custom client (advanced usage)
os.environ['CHOKED_REDIS_CLIENT'] = redis_client
```

## Multi-Process Example

Here's how multiple processes coordinate through Redis:

```python
# worker.py
import os
import time
from choked import choked

os.environ['CHOKED_REDIS_URL'] = 'redis://localhost:6379/0'

@choked(key="shared_api", max_tokens=100, refill_period=3600)  # 100/hour shared
def api_worker_task(worker_id):
    print(f"Worker {worker_id} making API call")
    # Simulate API call
    time.sleep(0.1)
    return f"Worker {worker_id} completed"

if __name__ == "__main__":
    import sys
    worker_id = sys.argv[1] if len(sys.argv) > 1 else "1"
    
    # Each worker competes for the same 100 tokens/hour
    for i in range(50):
        try:
            result = api_worker_task(worker_id)
            print(f"Success: {result}")
        except Exception as e:
            print(f"Rate limited: {e}")
```

Run multiple workers:
```bash
python worker.py worker1 &
python worker.py worker2 &
python worker.py worker3 &
```

All workers share the same rate limit automatically!

## Monitoring

### Redis Monitoring Commands

```bash
# Connect to Redis CLI
redis-cli

# Monitor all commands (useful for debugging)
MONITOR

# Check token bucket keys
KEYS choked:*

# Inspect a specific bucket
HGETALL choked:your_key_name

# Check Redis memory usage
INFO memory

# Monitor Redis performance
INFO stats
```

### Token Bucket Data Structure

Choked stores token buckets as Redis hashes:

```bash
redis-cli> HGETALL choked:api_calls
1) "tokens"
2) "8.5"
3) "last_refill"
4) "1640995200.123"
5) "max_tokens"
6) "10"
7) "refill_rate"
8) "0.16666666666666666"
```

## Troubleshooting

### Connection Issues

```python
# Test Redis connection
import redis

try:
    r = redis.from_url(os.environ['CHOKED_REDIS_URL'])
    r.ping()
    print("Redis connection successful")
except redis.ConnectionError as e:
    print(f"Redis connection failed: {e}")
```

### Performance Issues

```bash
# Check Redis latency
redis-cli --latency-history

# Monitor slow queries
redis-cli --latency

# Check if Redis is swapping
redis-cli INFO memory | grep used_memory_rss_human
```

### Common Problems

1. **Connection Refused**
   - Check if Redis is running: `redis-cli ping`
   - Verify port and host settings
   - Check firewall rules

2. **Authentication Failed**
   - Verify password in connection URL
   - Check Redis `requirepass` setting

3. **High Memory Usage**
   - Set appropriate `maxmemory` limit
   - Configure memory eviction policy
   - Monitor token bucket key expiration

4. **Network Timeouts**
   - Increase connection timeout settings
   - Check network latency to Redis server
   - Consider Redis connection pooling

## Production Best Practices

### Security
- Use strong passwords
- Enable SSL/TLS for remote connections
- Restrict network access with firewalls
- Regular security updates

### Performance
- Use Redis persistence for durability
- Monitor memory usage and set limits
- Use connection pooling for high-traffic applications
- Consider Redis Cluster for horizontal scaling

### Monitoring
- Set up Redis monitoring (e.g., Redis Insight, Prometheus)
- Monitor token bucket key patterns
- Track rate limiting effectiveness
- Alert on Redis availability issues

With Redis properly configured, Choked can seamlessly coordinate rate limits across your entire distributed application infrastructure.
